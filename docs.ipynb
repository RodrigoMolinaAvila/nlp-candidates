{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c01ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pypdf import PdfReader\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# -------- configuración --------\n",
    "BASE_DIR = Path(\"C:/Users/Rodrigo/Desktop/Rodrigo proyects/nlp-candidates\")\n",
    "assert BASE_DIR.exists(), f\"No existe: {BASE_DIR}\"\n",
    "OUT_DIR = Path.cwd()\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# -------- utilidades --------\n",
    "def normalizar(x):\n",
    "    if not x: return \"\"\n",
    "    x = x.replace(\"\\x00\",\"\")\n",
    "    x = re.sub(r\"[ \\t]+\",\" \", x)\n",
    "    x = re.sub(r\"\\s+\\n\",\"\\n\", x)\n",
    "    x = re.sub(r\"\\n{3,}\",\"\\n\\n\", x)\n",
    "    return x.strip()\n",
    "\n",
    "def candidato_desde_nombre(p):\n",
    "    return p.stem.lower()\n",
    "\n",
    "def leer_pdf_por_pagina(p):\n",
    "    try:\n",
    "        r = PdfReader(str(p))\n",
    "        out = []\n",
    "        for i in range(len(r.pages)):\n",
    "            t = r.pages[i].extract_text() or \"\"\n",
    "            out.append(t)\n",
    "        return out\n",
    "    except Exception as e:\n",
    "        print(\"ERROR leyendo\", p.name, \"->\", e)\n",
    "        return []\n",
    "\n",
    "# -------- extracción --------\n",
    "rows = []\n",
    "pdfs = sorted(BASE_DIR.glob(\"*.pdf\"))\n",
    "if not pdfs:\n",
    "    raise SystemExit(\"No se encontraron PDFs en la carpeta especificada.\")\n",
    "\n",
    "for p in pdfs:\n",
    "    pags = leer_pdf_por_pagina(p)\n",
    "    for i, txt in enumerate(pags, start=1):\n",
    "        rows.append({\n",
    "            \"candidate\": candidato_desde_nombre(p),\n",
    "            \"filename\": p.name,\n",
    "            \"page\": i,\n",
    "            \"text\": normalizar(txt)\n",
    "        })\n",
    "\n",
    "pages = pd.DataFrame(rows)\n",
    "if pages.empty:\n",
    "    raise SystemExit(\"No se extrajo texto. Revisa si los PDFs son escaneados (imagen).\")\n",
    "\n",
    "# métricas rápidas (útil para QC)\n",
    "pages[\"n_chars\"] = pages[\"text\"].str.len()\n",
    "pages[\"n_words\"] = pages[\"text\"].str.split().apply(len)\n",
    "\n",
    "# -------- agregación por documento --------\n",
    "docs = (pages\n",
    "        .sort_values([\"filename\",\"page\"])\n",
    "        .groupby([\"candidate\",\"filename\"], as_index=False)[\"text\"]\n",
    "        .apply(lambda s: \"\\n\\n\".join(s.values))\n",
    "       )\n",
    "docs[\"n_chars\"] = docs[\"text\"].str.len()\n",
    "docs[\"n_words\"] = docs[\"text\"].str.split().apply(len)\n",
    "\n",
    "# -------- persistencia en parquet y csv --------\n",
    "pages_parquet = OUT_DIR / \"pages.parquet\"\n",
    "docs_parquet  = OUT_DIR / \"documents.parquet\"\n",
    "pages_csv     = OUT_DIR / \"pages.csv\"\n",
    "docs_csv      = OUT_DIR / \"documents.csv\"\n",
    "\n",
    "pages.to_parquet(pages_parquet, index=False)\n",
    "docs.to_parquet(docs_parquet, index=False)\n",
    "\n",
    "# CSV en UTF-8 con BOM por compatibilidad amplia en Windows/Excel\n",
    "pages.to_csv(pages_csv, index=False, encoding=\"utf-8-sig\")\n",
    "docs.to_csv(docs_csv, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"Listo.\")\n",
    "print(\"Archivos generados:\")\n",
    "print(\" -\", pages_parquet)\n",
    "print(\" -\", docs_parquet)\n",
    "print(\" -\", pages_csv)\n",
    "print(\" -\", docs_csv)\n",
    "\n",
    "# -------- reporte rápido de PDFs sospechosos (posibles escaneos sin texto) --------\n",
    "print(\"\\nPosibles PDFs con poco texto (revisar OCR si aparecen arriba):\")\n",
    "print(pages.groupby(\"filename\")[\"n_words\"].sum().sort_values().head(10))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
