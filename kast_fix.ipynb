{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196c7ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% OCR de kast.pdf (ruta relativa) + export e integración\n",
    "!pip -q install pymupdf pillow pytesseract pandas pyarrow\n",
    "\n",
    "import io, re\n",
    "import fitz\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Fuerza el ejecutable si hace falta (ya lo tienes instalado)\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "print(\"Tesseract:\", pytesseract.get_tesseract_version())\n",
    "\n",
    "# --- Ruta relativa por defecto, con fallback a tu ruta absoluta (con espacios) ---\n",
    "PDF_PATH = Path(\"kast.pdf\")\n",
    "if not PDF_PATH.exists():\n",
    "    PDF_PATH = Path(r\"C:\\Users\\Rodrigo\\Desktop\\Rodrigo proyects\\nlp-candidates\\kast.pdf\")\n",
    "assert PDF_PATH.exists(), f\"No existe: {PDF_PATH}\"\n",
    "\n",
    "def normalizar(x):\n",
    "    if not x: return \"\"\n",
    "    x = x.replace(\"\\x00\",\"\")\n",
    "    x = re.sub(r\"[ \\t]+\",\" \", x)\n",
    "    x = re.sub(r\"\\s+\\n\",\"\\n\", x)\n",
    "    x = re.sub(r\"\\n{3,}\",\"\\n\\n\", x)\n",
    "    return x.strip()\n",
    "\n",
    "def ocr_pymupdf(pdf_path, lang=\"spa\", dpi=350, psm=6):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    rows = []\n",
    "    zoom = dpi / 72.0\n",
    "    mat = fitz.Matrix(zoom, zoom)\n",
    "    cfg = f\"--oem 3 --psm {psm}\"\n",
    "    for i in range(len(doc)):\n",
    "        pix = doc.load_page(i).get_pixmap(matrix=mat, alpha=False)\n",
    "        img = Image.open(io.BytesIO(pix.tobytes(\"png\")))\n",
    "        try:\n",
    "            txt = pytesseract.image_to_string(img, lang=lang, config=cfg) or \"\"\n",
    "        finally:\n",
    "            img.close()\n",
    "        rows.append({\"candidate\":\"kast\",\"filename\":PDF_PATH.name,\"page\":i+1,\"text\":normalizar(txt)})\n",
    "    doc.close()\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# OCR principal; si detecta poco texto, reintenta con layout por columnas\n",
    "pages_kast = ocr_pymupdf(PDF_PATH, lang=\"spa\", dpi=350, psm=6)\n",
    "if pages_kast[\"text\"].str.len().sum() < 5000:\n",
    "    pages_kast = ocr_pymupdf(PDF_PATH, lang=\"spa\", dpi=400, psm=4)\n",
    "\n",
    "# Métricas\n",
    "pages_kast[\"n_chars\"] = pages_kast[\"text\"].str.len()\n",
    "pages_kast[\"n_words\"] = pages_kast[\"text\"].str.split().apply(len)\n",
    "\n",
    "# Documento agregado\n",
    "docs_kast = (pages_kast\n",
    "             .sort_values([\"filename\",\"page\"])\n",
    "             .groupby([\"candidate\",\"filename\"], as_index=False)[\"text\"]\n",
    "             .apply(lambda s: \"\\n\\n\".join(s.values)))\n",
    "docs_kast[\"n_chars\"] = docs_kast[\"text\"].str.len()\n",
    "docs_kast[\"n_words\"] = docs_kast[\"text\"].str.split().apply(len)\n",
    "\n",
    "# Persistencia (en el cwd)\n",
    "pages_kast.to_parquet(\"kast_pages.parquet\", index=False)\n",
    "docs_kast.to_parquet(\"kast_document.parquet\", index=False)\n",
    "pages_kast.to_csv(\"kast_pages.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "docs_kast.to_csv(\"kast_document.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"Generados: kast_pages.{parquet,csv}, kast_document.{parquet,csv}\")\n",
    "\n",
    "# Integración opcional si existen tus datasets globales en el cwd\n",
    "if Path(\"pages.parquet\").exists() and Path(\"documents.parquet\").exists():\n",
    "    pages_all = pd.read_parquet(\"pages.parquet\")\n",
    "    docs_all  = pd.read_parquet(\"documents.parquet\")\n",
    "    pages_all = pd.concat([pages_all[pages_all.candidate!=\"kast\"], pages_kast], ignore_index=True)\n",
    "    docs_all  = pd.concat([docs_all[docs_all.candidate!=\"kast\"],  docs_kast],  ignore_index=True)\n",
    "    pages_all.to_parquet(\"pages.parquet\", index=False)\n",
    "    docs_all.to_parquet(\"documents.parquet\", index=False)\n",
    "    pages_all.to_csv(\"pages.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "    docs_all.to_csv(\"documents.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "    print(\"Corpus global actualizado: 'kast' reemplazado.\")\n",
    "\n",
    "print(\"\\nResumen kast (n_words):\")\n",
    "print(docs_kast[[\"candidate\",\"filename\",\"n_words\"]])\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
